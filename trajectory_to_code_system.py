#!/usr/bin/env python3
"""
OCR0712 è»Œè·¡æ¨¡æ“¬ç‚ºä»£ç¢¼ç³»çµ±
å°‡äººé¡æ‰‹å¯«è»Œè·¡è½‰æ›ç‚ºå¯åŸ·è¡Œçš„è­˜åˆ¥ä»£ç¢¼
"""

import numpy as np
import json
import time
from typing import Dict, List, Tuple, Any, Optional, Union
from dataclasses import dataclass, asdict
from pathlib import Path
import math

@dataclass
class HandwritingPoint:
    """æ‰‹å¯«è»Œè·¡é»"""
    x: float
    y: float
    pressure: float
    timestamp: float
    velocity: float = 0.0
    acceleration: float = 0.0
    
@dataclass
class HandwritingStroke:
    """æ‰‹å¯«ç­†ç•«"""
    points: List[HandwritingPoint]
    stroke_id: int
    character_part: str = ""
    confidence: float = 1.0
    
@dataclass
class HandwritingTrajectory:
    """å®Œæ•´æ‰‹å¯«è»Œè·¡"""
    strokes: List[HandwritingStroke]
    character: str
    bounding_box: Tuple[float, float, float, float]  # x1, y1, x2, y2
    total_time: float
    complexity_score: float = 0.0

class TrajectoryToCodeConverter:
    """è»Œè·¡è½‰ä»£ç¢¼è½‰æ›å™¨"""
    
    def __init__(self):
        self.code_templates = {
            'stroke_detection': self._load_stroke_templates(),
            'feature_extraction': self._load_feature_templates(),
            'recognition_logic': self._load_recognition_templates()
        }
        
    def _load_stroke_templates(self) -> Dict[str, str]:
        """è¼‰å…¥ç­†ç•«ä»£ç¢¼æ¨¡æ¿"""
        return {
            'horizontal': '''
def detect_horizontal_stroke(points, threshold=0.1):
    """æª¢æ¸¬æ©«ç•«"""
    if len(points) < 2:
        return False
    
    y_variance = np.var([p.y for p in points])
    x_range = max([p.x for p in points]) - min([p.x for p in points])
    
    return y_variance < threshold and x_range > threshold * 5
''',
            'vertical': '''
def detect_vertical_stroke(points, threshold=0.1):
    """æª¢æ¸¬è±ç•«"""
    if len(points) < 2:
        return False
    
    x_variance = np.var([p.x for p in points])
    y_range = max([p.y for p in points]) - min([p.y for p in points])
    
    return x_variance < threshold and y_range > threshold * 5
''',
            'dot': '''
def detect_dot_stroke(points, threshold=0.05):
    """æª¢æ¸¬é»"""
    if len(points) < 1:
        return False
    
    if len(points) == 1:
        return True
        
    x_range = max([p.x for p in points]) - min([p.x for p in points])
    y_range = max([p.y for p in points]) - min([p.y for p in points])
    
    return x_range < threshold and y_range < threshold
''',
            'curve': '''
def detect_curve_stroke(points, curvature_threshold=0.3):
    """æª¢æ¸¬å¼§ç·š"""
    if len(points) < 3:
        return False
    
    # è¨ˆç®—æ›²ç‡
    curvatures = []
    for i in range(1, len(points) - 1):
        p1, p2, p3 = points[i-1], points[i], points[i+1]
        
        # å‘é‡è¨ˆç®—
        v1 = (p2.x - p1.x, p2.y - p1.y)
        v2 = (p3.x - p2.x, p3.y - p2.y)
        
        # è§’åº¦è®ŠåŒ–
        cross_product = v1[0] * v2[1] - v1[1] * v2[0]
        dot_product = v1[0] * v2[0] + v1[1] * v2[1]
        
        angle = math.atan2(cross_product, dot_product)
        curvatures.append(abs(angle))
    
    avg_curvature = np.mean(curvatures) if curvatures else 0
    return avg_curvature > curvature_threshold
'''
        }
    
    def _load_feature_templates(self) -> Dict[str, str]:
        """è¼‰å…¥ç‰¹å¾µæå–ä»£ç¢¼æ¨¡æ¿"""
        return {
            'basic_features': '''
def extract_basic_features(trajectory):
    """æå–åŸºæœ¬ç‰¹å¾µ"""
    features = {}
    
    # ç­†ç•«æ•¸é‡
    features['stroke_count'] = len(trajectory.strokes)
    
    # ç¸½é»æ•¸
    total_points = sum(len(stroke.points) for stroke in trajectory.strokes)
    features['total_points'] = total_points
    
    # æ›¸å¯«æ™‚é–“
    features['total_time'] = trajectory.total_time
    
    # é‚Šç•Œæ¡†ç‰¹å¾µ
    bbox = trajectory.bounding_box
    features['width'] = bbox[2] - bbox[0]
    features['height'] = bbox[3] - bbox[1]
    features['aspect_ratio'] = features['width'] / max(features['height'], 1e-6)
    
    # è¤‡é›œåº¦
    features['complexity_score'] = trajectory.complexity_score
    
    return features
''',
            'velocity_features': '''
def extract_velocity_features(trajectory):
    """æå–é€Ÿåº¦ç‰¹å¾µ"""
    all_velocities = []
    
    for stroke in trajectory.strokes:
        for point in stroke.points:
            all_velocities.append(point.velocity)
    
    features = {}
    if all_velocities:
        features['avg_velocity'] = np.mean(all_velocities)
        features['max_velocity'] = np.max(all_velocities)
        features['min_velocity'] = np.min(all_velocities)
        features['velocity_variance'] = np.var(all_velocities)
    else:
        features.update({
            'avg_velocity': 0, 'max_velocity': 0, 
            'min_velocity': 0, 'velocity_variance': 0
        })
    
    return features
''',
            'pressure_features': '''
def extract_pressure_features(trajectory):
    """æå–å£“åŠ›ç‰¹å¾µ"""
    all_pressures = []
    
    for stroke in trajectory.strokes:
        for point in stroke.points:
            all_pressures.append(point.pressure)
    
    features = {}
    if all_pressures:
        features['avg_pressure'] = np.mean(all_pressures)
        features['max_pressure'] = np.max(all_pressures)
        features['pressure_variance'] = np.var(all_pressures)
        features['pressure_peaks'] = len([p for p in all_pressures if p > np.mean(all_pressures) + np.std(all_pressures)])
    else:
        features.update({
            'avg_pressure': 0, 'max_pressure': 0, 
            'pressure_variance': 0, 'pressure_peaks': 0
        })
    
    return features
'''
        }
    
    def _load_recognition_templates(self) -> Dict[str, str]:
        """è¼‰å…¥è­˜åˆ¥é‚è¼¯ä»£ç¢¼æ¨¡æ¿"""
        return {
            'simple_classifier': '''
def simple_character_classifier(features):
    """ç°¡å–®å­—ç¬¦åˆ†é¡å™¨"""
    
    # åŸºæ–¼è¦å‰‡çš„åˆ†é¡
    stroke_count = features.get('stroke_count', 0)
    aspect_ratio = features.get('aspect_ratio', 1.0)
    complexity = features.get('complexity_score', 0.0)
    
    # æ•¸å­—è­˜åˆ¥
    if stroke_count == 1:
        if aspect_ratio > 2.0:
            return "ä¸€", 0.9
        elif complexity < 0.3:
            return "ä¸¨", 0.8
        else:
            return "ä¹™", 0.7
    
    elif stroke_count == 2:
        if aspect_ratio > 1.5:
            return "äºŒ", 0.9
        elif features.get('has_curve', False):
            return "ä¹ƒ", 0.8
        else:
            return "å", 0.85
    
    elif stroke_count == 3:
        if aspect_ratio > 1.5:
            return "ä¸‰", 0.9
        elif complexity > 0.5:
            return "å±±", 0.8
        else:
            return "å·¥", 0.75
    
    # é»˜èªè¿”å›
    return "æœªçŸ¥", 0.1
''',
            'ml_classifier': '''
def ml_character_classifier(features, model):
    """æ©Ÿå™¨å­¸ç¿’å­—ç¬¦åˆ†é¡å™¨"""
    
    # ç‰¹å¾µæ¨™æº–åŒ–
    feature_vector = np.array([
        features.get('stroke_count', 0),
        features.get('aspect_ratio', 1.0),
        features.get('complexity_score', 0.0),
        features.get('avg_velocity', 0.0),
        features.get('avg_pressure', 0.0),
        features.get('width', 0.0),
        features.get('height', 0.0)
    ])
    
    # æ¨¡å‹é æ¸¬
    try:
        prediction = model.predict(feature_vector.reshape(1, -1))
        confidence = model.predict_proba(feature_vector.reshape(1, -1)).max()
        return prediction[0], confidence
    except:
        return "æœªçŸ¥", 0.1
''',
            'ensemble_classifier': '''
def ensemble_character_classifier(features, models_dict):
    """é›†æˆå­—ç¬¦åˆ†é¡å™¨"""
    
    predictions = []
    confidences = []
    
    # è¦å‰‡åˆ†é¡å™¨
    rule_pred, rule_conf = simple_character_classifier(features)
    predictions.append(rule_pred)
    confidences.append(rule_conf * 0.3)  # æ¬Šé‡0.3
    
    # MLåˆ†é¡å™¨
    if 'ml_model' in models_dict:
        ml_pred, ml_conf = ml_character_classifier(features, models_dict['ml_model'])
        predictions.append(ml_pred)
        confidences.append(ml_conf * 0.5)  # æ¬Šé‡0.5
    
    # æ·±åº¦å­¸ç¿’åˆ†é¡å™¨
    if 'dl_model' in models_dict:
        dl_pred, dl_conf = dl_character_classifier(features, models_dict['dl_model'])
        predictions.append(dl_pred)
        confidences.append(dl_conf * 0.2)  # æ¬Šé‡0.2
    
    # æŠ•ç¥¨æ©Ÿåˆ¶
    if len(set(predictions)) == 1:
        return predictions[0], max(confidences)
    else:
        # åŠ æ¬ŠæŠ•ç¥¨
        weighted_scores = {}
        for pred, conf in zip(predictions, confidences):
            weighted_scores[pred] = weighted_scores.get(pred, 0) + conf
        
        best_pred = max(weighted_scores, key=weighted_scores.get)
        best_conf = weighted_scores[best_pred] / sum(confidences)
        
        return best_pred, best_conf
'''
        }
    
    def trajectory_to_code(self, trajectory: HandwritingTrajectory) -> str:
        """å°‡è»Œè·¡è½‰æ›ç‚ºä»£ç¢¼"""
        
        code_sections = []
        
        # å°å…¥éƒ¨åˆ†
        code_sections.append(self._generate_imports())
        
        # æ•¸æ“šçµæ§‹å®šç¾©
        code_sections.append(self._generate_data_structures(trajectory))
        
        # ç­†ç•«æª¢æ¸¬ä»£ç¢¼
        code_sections.append(self._generate_stroke_detection_code(trajectory))
        
        # ç‰¹å¾µæå–ä»£ç¢¼  
        code_sections.append(self._generate_feature_extraction_code(trajectory))
        
        # è­˜åˆ¥é‚è¼¯ä»£ç¢¼
        code_sections.append(self._generate_recognition_code(trajectory))
        
        # ä¸»å‡½æ•¸
        code_sections.append(self._generate_main_function(trajectory))
        
        return "\n\n".join(code_sections)
    
    def _generate_imports(self) -> str:
        """ç”Ÿæˆå°å…¥ä»£ç¢¼"""
        return '''import numpy as np
import math
from typing import List, Tuple, Dict, Any
from dataclasses import dataclass

@dataclass
class Point:
    x: float
    y: float
    pressure: float
    timestamp: float
    velocity: float = 0.0'''
    
    def _generate_data_structures(self, trajectory: HandwritingTrajectory) -> str:
        """ç”Ÿæˆæ•¸æ“šçµæ§‹ä»£ç¢¼"""
        
        code = "# è»Œè·¡æ•¸æ“š\n"
        code += f"TARGET_CHARACTER = '{trajectory.character}'\n"
        code += f"STROKE_COUNT = {len(trajectory.strokes)}\n"
        code += f"TOTAL_TIME = {trajectory.total_time:.3f}\n"
        code += f"BOUNDING_BOX = {trajectory.bounding_box}\n\n"
        
        # ç”Ÿæˆè»Œè·¡é»æ•¸æ“š
        code += "TRAJECTORY_DATA = [\n"
        for stroke_idx, stroke in enumerate(trajectory.strokes):
            code += f"    # Stroke {stroke_idx + 1}\n"
            code += "    [\n"
            for point in stroke.points:
                code += f"        Point({point.x:.3f}, {point.y:.3f}, {point.pressure:.3f}, {point.timestamp:.3f}, {point.velocity:.3f}),\n"
            code += "    ],\n"
        code += "]\n"
        
        return code
    
    def _generate_stroke_detection_code(self, trajectory: HandwritingTrajectory) -> str:
        """ç”Ÿæˆç­†ç•«æª¢æ¸¬ä»£ç¢¼"""
        
        code = "# ç­†ç•«æª¢æ¸¬å‡½æ•¸\n"
        
        # åˆ†æè»Œè·¡ä¸­åŒ…å«çš„ç­†ç•«é¡å‹
        stroke_types = self._analyze_stroke_types(trajectory)
        
        for stroke_type in stroke_types:
            if stroke_type in self.code_templates['stroke_detection']:
                code += self.code_templates['stroke_detection'][stroke_type]
                code += "\n"
        
        # ç”Ÿæˆç­†ç•«åˆ†æå‡½æ•¸
        code += '''
def analyze_strokes(trajectory_data):
    """åˆ†ææ‰€æœ‰ç­†ç•«"""
    stroke_analysis = []
    
    for stroke_idx, stroke_points in enumerate(trajectory_data):
        analysis = {
            'stroke_id': stroke_idx,
            'point_count': len(stroke_points),
        }
        
        # æª¢æ¸¬ç­†ç•«é¡å‹
'''
        
        for stroke_type in stroke_types:
            code += f"        analysis['{stroke_type}'] = detect_{stroke_type}_stroke(stroke_points)\n"
        
        code += '''        
        stroke_analysis.append(analysis)
    
    return stroke_analysis
'''
        
        return code
    
    def _generate_feature_extraction_code(self, trajectory: HandwritingTrajectory) -> str:
        """ç”Ÿæˆç‰¹å¾µæå–ä»£ç¢¼"""
        
        code = "# ç‰¹å¾µæå–å‡½æ•¸\n"
        
        # æ ¹æ“šè»Œè·¡ç‰¹æ€§é¸æ“‡ç‰¹å¾µ
        feature_types = self._select_feature_types(trajectory)
        
        for feature_type in feature_types:
            if feature_type in self.code_templates['feature_extraction']:
                code += self.code_templates['feature_extraction'][feature_type]
                code += "\n"
        
        # ç”Ÿæˆç¶œåˆç‰¹å¾µæå–å‡½æ•¸
        code += '''
def extract_all_features(trajectory_data, stroke_analysis):
    """æå–æ‰€æœ‰ç‰¹å¾µ"""
    features = {}
    
    # æ§‹å»ºè»Œè·¡å°è±¡
    class MockTrajectory:
        def __init__(self):
            self.strokes = []
            self.total_time = TOTAL_TIME
            self.bounding_box = BOUNDING_BOX
            self.complexity_score = calculate_complexity_score(trajectory_data)
            
            for stroke_points in trajectory_data:
                stroke = type('MockStroke', (), {'points': stroke_points})()
                self.strokes.append(stroke)
    
    trajectory = MockTrajectory()
    
    # æå–å„ç¨®ç‰¹å¾µ
'''
        
        for feature_type in feature_types:
            code += f"    features.update(extract_{feature_type.replace('_features', '')}_features(trajectory))\n"
        
        code += '''    
    return features

def calculate_complexity_score(trajectory_data):
    """è¨ˆç®—å¾©é›œåº¦åˆ†æ•¸"""
    total_points = sum(len(stroke) for stroke in trajectory_data)
    total_direction_changes = 0
    
    for stroke in trajectory_data:
        for i in range(1, len(stroke) - 1):
            # è¨ˆç®—æ–¹å‘è®ŠåŒ–
            v1 = (stroke[i].x - stroke[i-1].x, stroke[i].y - stroke[i-1].y)
            v2 = (stroke[i+1].x - stroke[i].x, stroke[i+1].y - stroke[i].y)
            
            cross_product = v1[0] * v2[1] - v1[1] * v2[0]
            if abs(cross_product) > 0.1:  # é–¾å€¼
                total_direction_changes += 1
    
    return total_direction_changes / max(total_points, 1)
'''
        
        return code
    
    def _generate_recognition_code(self, trajectory: HandwritingTrajectory) -> str:
        """ç”Ÿæˆè­˜åˆ¥ä»£ç¢¼"""
        
        code = "# å­—ç¬¦è­˜åˆ¥å‡½æ•¸\n"
        
        # é¸æ“‡è­˜åˆ¥æ–¹æ³•
        recognition_method = self._select_recognition_method(trajectory)
        
        if recognition_method in self.code_templates['recognition_logic']:
            code += self.code_templates['recognition_logic'][recognition_method]
            code += "\n"
        
        # ç”Ÿæˆç‰¹å®šå­—ç¬¦çš„è­˜åˆ¥é‚è¼¯
        code += self._generate_character_specific_logic(trajectory)
        
        return code
    
    def _generate_character_specific_logic(self, trajectory: HandwritingTrajectory) -> str:
        """ç”Ÿæˆç‰¹å®šå­—ç¬¦çš„è­˜åˆ¥é‚è¼¯"""
        
        char = trajectory.character
        stroke_count = len(trajectory.strokes)
        
        code = f'''
def recognize_character_{ord(char)}(features, stroke_analysis):
    """è­˜åˆ¥å­—ç¬¦ '{char}' çš„å°ˆé–€å‡½æ•¸"""
    
    # å­—ç¬¦ç‰¹å®šçš„ç‰¹å¾µæª¢æŸ¥
    expected_stroke_count = {stroke_count}
    actual_stroke_count = features.get('stroke_count', 0)
    
    if actual_stroke_count != expected_stroke_count:
        return '{char}', 0.3  # ä½ç½®ä¿¡åº¦
    
    # è©³ç´°ç‰¹å¾µåŒ¹é…
    confidence = 0.5  # åŸºç¤ç½®ä¿¡åº¦
    
'''
        
        # æ ¹æ“šå­—ç¬¦å¾©é›œåº¦æ·»åŠ ç‰¹å®šæª¢æŸ¥
        if trajectory.complexity_score > 0.5:
            code += '''    # é«˜å¾©é›œåº¦å­—ç¬¦æª¢æŸ¥
    if features.get('complexity_score', 0) > 0.4:
        confidence += 0.2
    
'''
        
        # æ ¹æ“šç­†ç•«ç‰¹æ€§æ·»åŠ æª¢æŸ¥
        if len(trajectory.strokes) > 1:
            code += '''    # å¤šç­†ç•«å­—ç¬¦æª¢æŸ¥
    stroke_consistency = sum(1 for s in stroke_analysis if s.get('horizontal', False) or s.get('vertical', False))
    if stroke_consistency > 0:
        confidence += 0.2
    
'''
        
        code += f'''    return '{char}', min(confidence, 0.95)
'''
        
        return code
    
    def _generate_main_function(self, trajectory: HandwritingTrajectory) -> str:
        """ç”Ÿæˆä¸»å‡½æ•¸"""
        
        code = '''
def main():
    """ä¸»è­˜åˆ¥å‡½æ•¸"""
    print(f"é–‹å§‹è­˜åˆ¥å­—ç¬¦è»Œè·¡ï¼Œç›®æ¨™å­—ç¬¦: {TARGET_CHARACTER}")
    
    # ç­†ç•«åˆ†æ
    stroke_analysis = analyze_strokes(TRAJECTORY_DATA)
    print(f"æª¢æ¸¬åˆ° {len(stroke_analysis)} å€‹ç­†ç•«")
    
    # ç‰¹å¾µæå–
    features = extract_all_features(TRAJECTORY_DATA, stroke_analysis)
    print(f"æå–ç‰¹å¾µ: {list(features.keys())}")
    
    # å­—ç¬¦è­˜åˆ¥
'''
        
        char_code = ord(trajectory.character)
        code += f'''    predicted_char, confidence = recognize_character_{char_code}(features, stroke_analysis)
    
    # çµæœè¼¸å‡º
    print(f"è­˜åˆ¥çµæœ: {{predicted_char}}")
    print(f"ç½®ä¿¡åº¦: {{confidence:.3f}}")
    print(f"ç›®æ¨™å­—ç¬¦: {{TARGET_CHARACTER}}")
    print(f"è­˜åˆ¥æ­£ç¢º: {{predicted_char == TARGET_CHARACTER}}")
    
    return predicted_char, confidence

if __name__ == "__main__":
    main()
'''
        
        return code
    
    def _analyze_stroke_types(self, trajectory: HandwritingTrajectory) -> List[str]:
        """åˆ†æè»Œè·¡ä¸­çš„ç­†ç•«é¡å‹"""
        stroke_types = set()
        
        for stroke in trajectory.strokes:
            if len(stroke.points) <= 2:
                stroke_types.add('dot')
            else:
                # ç°¡åŒ–çš„ç­†ç•«é¡å‹æª¢æ¸¬
                x_range = max(p.x for p in stroke.points) - min(p.x for p in stroke.points)
                y_range = max(p.y for p in stroke.points) - min(p.y for p in stroke.points)
                
                if x_range > y_range * 2:
                    stroke_types.add('horizontal')
                elif y_range > x_range * 2:
                    stroke_types.add('vertical')
                else:
                    stroke_types.add('curve')
        
        return list(stroke_types)
    
    def _select_feature_types(self, trajectory: HandwritingTrajectory) -> List[str]:
        """é¸æ“‡ç‰¹å¾µé¡å‹"""
        feature_types = ['basic_features']
        
        # æ ¹æ“šè»Œè·¡ç‰¹æ€§é¸æ“‡ç‰¹å¾µ
        if any(point.velocity > 0 for stroke in trajectory.strokes for point in stroke.points):
            feature_types.append('velocity_features')
        
        if any(point.pressure > 0 for stroke in trajectory.strokes for point in stroke.points):
            feature_types.append('pressure_features')
        
        return feature_types
    
    def _select_recognition_method(self, trajectory: HandwritingTrajectory) -> str:
        """é¸æ“‡è­˜åˆ¥æ–¹æ³•"""
        # æ ¹æ“šå¾©é›œåº¦é¸æ“‡è­˜åˆ¥æ–¹æ³•
        if trajectory.complexity_score > 0.7:
            return 'ensemble_classifier'
        elif len(trajectory.strokes) > 5:
            return 'ml_classifier'
        else:
            return 'simple_classifier'

class TrajectorySimulator:
    """è»Œè·¡æ¨¡æ“¬å™¨"""
    
    def __init__(self):
        self.converter = TrajectoryToCodeConverter()
    
    def create_sample_trajectory(self, character: str, complexity: float = 0.5) -> HandwritingTrajectory:
        """å‰µå»ºç¤ºä¾‹è»Œè·¡"""
        
        strokes = []
        
        # æ ¹æ“šå­—ç¬¦å‰µå»ºä¸åŒçš„ç­†ç•«æ¨¡å¼
        if character == "ä¸€":
            # æ©«ç•«
            points = [
                HandwritingPoint(0.1, 0.5, 0.8, 0.0, 1.0),
                HandwritingPoint(0.5, 0.5, 0.9, 0.5, 1.2),
                HandwritingPoint(0.9, 0.5, 0.7, 1.0, 0.8)
            ]
            strokes.append(HandwritingStroke(points, 0, "horizontal"))
            
        elif character == "å":
            # æ©«ç•«
            h_points = [
                HandwritingPoint(0.2, 0.4, 0.8, 0.0, 1.0),
                HandwritingPoint(0.8, 0.4, 0.8, 0.5, 1.0)
            ]
            strokes.append(HandwritingStroke(h_points, 0, "horizontal"))
            
            # è±ç•«
            v_points = [
                HandwritingPoint(0.5, 0.1, 0.9, 1.0, 1.1),
                HandwritingPoint(0.5, 0.7, 0.8, 1.5, 0.9)
            ]
            strokes.append(HandwritingStroke(v_points, 1, "vertical"))
            
        elif character == "å±±":
            # ä¸‰å€‹è±ç•«
            for i, x_pos in enumerate([0.2, 0.5, 0.8]):
                points = [
                    HandwritingPoint(x_pos, 0.1, 0.8, i * 0.7, 1.0),
                    HandwritingPoint(x_pos, 0.6, 0.9, i * 0.7 + 0.5, 1.0)
                ]
                strokes.append(HandwritingStroke(points, i, "vertical"))
                
        else:
            # é»˜èªç°¡å–®è»Œè·¡
            points = [
                HandwritingPoint(0.3, 0.3, 0.8, 0.0, 1.0),
                HandwritingPoint(0.7, 0.7, 0.9, 0.5, 1.0)
            ]
            strokes.append(HandwritingStroke(points, 0, "curve"))
        
        # è¨ˆç®—é‚Šç•Œæ¡†
        all_x = [p.x for stroke in strokes for p in stroke.points]
        all_y = [p.y for stroke in strokes for p in stroke.points]
        bbox = (min(all_x), min(all_y), max(all_x), max(all_y))
        
        # è¨ˆç®—ç¸½æ™‚é–“
        total_time = max(p.timestamp for stroke in strokes for p in stroke.points)
        
        return HandwritingTrajectory(
            strokes=strokes,
            character=character,
            bounding_box=bbox,
            total_time=total_time,
            complexity_score=complexity
        )
    
    def simulate_and_generate_code(self, character: str, complexity: float = 0.5) -> str:
        """æ¨¡æ“¬è»Œè·¡ä¸¦ç”Ÿæˆä»£ç¢¼"""
        
        print(f"ğŸ¯ é–‹å§‹æ¨¡æ“¬å­—ç¬¦ '{character}' çš„æ‰‹å¯«è»Œè·¡...")
        
        # å‰µå»ºè»Œè·¡
        trajectory = self.create_sample_trajectory(character, complexity)
        
        print(f"ğŸ“ ç”Ÿæˆè»Œè·¡: {len(trajectory.strokes)} å€‹ç­†ç•«, è¤‡é›œåº¦: {complexity:.2f}")
        
        # è½‰æ›ç‚ºä»£ç¢¼
        generated_code = self.converter.trajectory_to_code(trajectory)
        
        print(f"ğŸ”§ ä»£ç¢¼ç”Ÿæˆå®Œæˆï¼Œå…± {len(generated_code.split('\\n'))} è¡Œ")
        
        return generated_code
    
    def batch_simulate(self, characters: List[str], output_dir: str = "generated_ocr_codes"):
        """æ‰¹é‡æ¨¡æ“¬ä¸¦ç”Ÿæˆä»£ç¢¼"""
        
        output_path = Path(output_dir)
        output_path.mkdir(exist_ok=True)
        
        print(f"ğŸš€ é–‹å§‹æ‰¹é‡æ¨¡æ“¬ {len(characters)} å€‹å­—ç¬¦...")
        
        for i, char in enumerate(characters):
            print(f"\\nè™•ç†å­—ç¬¦ {i+1}/{len(characters)}: '{char}'")
            
            # éš¨æ©Ÿå¾©é›œåº¦
            complexity = np.random.uniform(0.3, 0.8)
            
            # ç”Ÿæˆä»£ç¢¼
            code = self.simulate_and_generate_code(char, complexity)
            
            # ä¿å­˜ä»£ç¢¼
            filename = f"ocr_recognize_{ord(char)}_{char}.py"
            filepath = output_path / filename
            
            with open(filepath, 'w', encoding='utf-8') as f:
                f.write(f"# OCRè­˜åˆ¥ä»£ç¢¼ - å­—ç¬¦: {char}\\n")
                f.write(f"# è‡ªå‹•ç”Ÿæˆæ™‚é–“: {time.strftime('%Y-%m-%d %H:%M:%S')}\\n")
                f.write(f"# è¤‡é›œåº¦: {complexity:.3f}\\n\\n")
                f.write(code)
            
            print(f"âœ… ä»£ç¢¼å·²ä¿å­˜: {filepath}")
        
        # ç”Ÿæˆæ‰¹é‡æ¸¬è©¦è…³æœ¬
        self._generate_batch_test_script(characters, output_path)
        
        print(f"\\nğŸ‰ æ‰¹é‡æ¨¡æ“¬å®Œæˆ! æ‰€æœ‰æ–‡ä»¶ä¿å­˜åœ¨: {output_path}")
    
    def _generate_batch_test_script(self, characters: List[str], output_dir: Path):
        """ç”Ÿæˆæ‰¹é‡æ¸¬è©¦è…³æœ¬"""
        
        test_script = '''#!/usr/bin/env python3
"""
OCRè»Œè·¡æ¨¡æ“¬æ‰¹é‡æ¸¬è©¦è…³æœ¬
"""

import os
import sys
import importlib.util
import time

def test_generated_codes():
    """æ¸¬è©¦æ‰€æœ‰ç”Ÿæˆçš„è­˜åˆ¥ä»£ç¢¼"""
    
    print("ğŸ”„ é–‹å§‹æ‰¹é‡æ¸¬è©¦ç”Ÿæˆçš„OCRä»£ç¢¼...")
    
    results = []
    test_files = [f for f in os.listdir('.') if f.startswith('ocr_recognize_') and f.endswith('.py')]
    
    for i, filename in enumerate(test_files):
        print(f"\\næ¸¬è©¦ {i+1}/{len(test_files)}: {filename}")
        
        try:
            # å‹•æ…‹å°å…¥æ¨¡å¡Š
            spec = importlib.util.spec_from_file_location("test_module", filename)
            module = importlib.util.module_from_spec(spec)
            spec.loader.exec_module(module)
            
            # åŸ·è¡Œä¸»å‡½æ•¸
            start_time = time.time()
            predicted_char, confidence = module.main()
            execution_time = time.time() - start_time
            
            # ç²å–ç›®æ¨™å­—ç¬¦
            target_char = module.TARGET_CHARACTER
            
            # è¨˜éŒ„çµæœ
            result = {
                'filename': filename,
                'target_char': target_char,
                'predicted_char': predicted_char,
                'confidence': confidence,
                'execution_time': execution_time,
                'success': predicted_char == target_char
            }
            results.append(result)
            
            status = "âœ…" if result['success'] else "âŒ"
            print(f"{status} çµæœ: {predicted_char} (ç½®ä¿¡åº¦: {confidence:.3f}, æ™‚é–“: {execution_time:.3f}s)")
            
        except Exception as e:
            print(f"âŒ éŒ¯èª¤: {e}")
            results.append({
                'filename': filename,
                'error': str(e),
                'success': False
            })
    
    # çµ±è¨ˆçµæœ
    successful = sum(1 for r in results if r.get('success', False))
    total = len(results)
    
    print(f"\\nğŸ“Š === æ‰¹é‡æ¸¬è©¦çµæœ ===")
    print(f"ç¸½æ¸¬è©¦æ•¸: {total}")
    print(f"æˆåŠŸæ•¸: {successful}")
    print(f"æˆåŠŸç‡: {successful/total*100:.1f}%")
    
    if successful > 0:
        avg_confidence = sum(r.get('confidence', 0) for r in results if r.get('success', False)) / successful
        avg_time = sum(r.get('execution_time', 0) for r in results if r.get('success', False)) / successful
        print(f"å¹³å‡ç½®ä¿¡åº¦: {avg_confidence:.3f}")
        print(f"å¹³å‡åŸ·è¡Œæ™‚é–“: {avg_time:.3f}s")
    
    return results

if __name__ == "__main__":
    test_generated_codes()
'''
        
        test_script_path = output_dir / "batch_test.py"
        with open(test_script_path, 'w', encoding='utf-8') as f:
            f.write(test_script)
        
        # æ·»åŠ åŸ·è¡Œæ¬Šé™
        import os
        os.chmod(test_script_path, 0o755)
        
        print(f"ğŸ“‹ æ‰¹é‡æ¸¬è©¦è…³æœ¬å·²ç”Ÿæˆ: {test_script_path}")

def main():
    """ä¸»å‡½æ•¸æ¼”ç¤º"""
    
    print("ğŸ¯ === OCR0712 è»Œè·¡æ¨¡æ“¬ç‚ºä»£ç¢¼ç³»çµ±æ¼”ç¤º ===")
    print()
    
    simulator = TrajectorySimulator()
    
    # æ¼”ç¤ºå–®å€‹å­—ç¬¦
    print("ğŸ“ æ¼”ç¤ºå–®å€‹å­—ç¬¦æ¨¡æ“¬...")
    code = simulator.simulate_and_generate_code("å", complexity=0.6)
    
    # ä¿å­˜ç¤ºä¾‹ä»£ç¢¼
    with open("example_trajectory_code.py", 'w', encoding='utf-8') as f:
        f.write("# OCRè»Œè·¡æ¨¡æ“¬ç¤ºä¾‹ä»£ç¢¼\\n\\n")
        f.write(code)
    
    print("âœ… ç¤ºä¾‹ä»£ç¢¼å·²ä¿å­˜: example_trajectory_code.py")
    
    # æ¼”ç¤ºæ‰¹é‡æ¨¡æ“¬
    print("\\nğŸš€ æ¼”ç¤ºæ‰¹é‡å­—ç¬¦æ¨¡æ“¬...")
    test_characters = ["ä¸€", "å", "å±±", "å·¥", "ä¸‰", "äºŒ", "äºº", "å¤§", "å°"]
    
    simulator.batch_simulate(test_characters, "trajectory_codes")
    
    print("\\nğŸ‰ è»Œè·¡æ¨¡æ“¬æ¼”ç¤ºå®Œæˆ!")
    print("ğŸ“ æŸ¥çœ‹ trajectory_codes/ ç›®éŒ„ç²å–æ‰€æœ‰ç”Ÿæˆçš„è­˜åˆ¥ä»£ç¢¼")

if __name__ == "__main__":
    main()